package memory

import (
	applog "flowweave/internal/platform/log"
	"context"
	"fmt"
	"strings"

	"flowweave/internal/provider"
)

// LLMSummaryGenerator ä½¿ç”¨ LLM ç”Ÿæˆå¯¹è¯æ‘˜è¦
type LLMSummaryGenerator struct {
	providerName string // LLM provider åç§°
	modelName    string // æ¨¡å‹åç§°
}

// NewLLMSummaryGenerator åˆ›å»º LLM æ‘˜è¦ç”Ÿæˆå™¨
func NewLLMSummaryGenerator(providerName, modelName string) *LLMSummaryGenerator {
	applog.Info("[Summary/LLM] Generator initialized",
		"provider", providerName,
		"model", modelName,
	)
	return &LLMSummaryGenerator{
		providerName: providerName,
		modelName:    modelName,
	}
}

// Summarize æ ¹æ®å¯¹è¯æ¶ˆæ¯ç”Ÿæˆ/æ›´æ–°æ‘˜è¦
func (g *LLMSummaryGenerator) Summarize(ctx context.Context, messages []Message, existingSummary string) (string, error) {
	applog.Info("[Summary/LLM] ğŸ¤– Starting summary generation",
		"provider", g.providerName,
		"model", g.modelName,
		"message_count", len(messages),
		"has_existing_summary", existingSummary != "",
	)

	llmProvider, err := provider.GetProvider(g.providerName)
	if err != nil {
		applog.Error("[Summary/LLM] âŒ Failed to get provider",
			"provider", g.providerName,
			"error", err,
		)
		return "", fmt.Errorf("get summary provider: %w", err)
	}

	// æ„å»ºæ‘˜è¦æç¤º
	prompt := g.buildSummaryPrompt(messages, existingSummary)

	promptPreview := prompt
	if len(promptPreview) > 300 {
		promptPreview = promptPreview[:300] + "..."
	}
	applog.Debug("[Summary/LLM] Prompt built",
		"prompt_length", len(prompt),
		"prompt_preview", promptPreview,
	)

	req := &provider.CompletionRequest{
		Model: g.modelName,
		Messages: []provider.Message{
			{Role: "system", Content: summarySystemPrompt},
			{Role: "user", Content: prompt},
		},
		Temperature: 0.3, // ä½æ¸©åº¦ä¿è¯ç¨³å®šæ‘˜è¦
		MaxTokens:   500,
	}

	applog.Debug("[Summary/LLM] Calling LLM...",
		"model", g.modelName,
		"temperature", req.Temperature,
		"max_tokens", req.MaxTokens,
	)

	resp, err := llmProvider.Complete(ctx, req)
	if err != nil {
		applog.Error("[Summary/LLM] âŒ LLM call failed",
			"provider", g.providerName,
			"model", g.modelName,
			"error", err,
		)
		return "", fmt.Errorf("summary generation failed: %w", err)
	}

	result := strings.TrimSpace(resp.Content)

	resultPreview := result
	if len(resultPreview) > 300 {
		resultPreview = resultPreview[:300] + "..."
	}
	applog.Info("[Summary/LLM] âœ… Summary generated",
		"provider", g.providerName,
		"model", g.modelName,
		"summary_length", len(result),
		"summary_preview", resultPreview,
	)

	return result, nil
}

const summarySystemPrompt = `ä½ æ˜¯ä¸€ä¸ªå¯¹è¯æ‘˜è¦åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†å¯¹è¯å†…å®¹å‹ç¼©ä¸ºç®€æ´çš„æ‘˜è¦ï¼Œä¿ç•™å…³é”®ä¿¡æ¯å’Œä¸Šä¸‹æ–‡ã€‚
è¦æ±‚ï¼š
1. ä¿ç•™å¯¹è¯ä¸­çš„å…³é”®äº‹å®ã€å†³ç­–å’Œç»“è®º
2. ä¿ç•™ç”¨æˆ·çš„åå¥½å’Œéœ€æ±‚
3. ä½¿ç”¨ç®€æ´çš„è¯­è¨€ï¼Œé¿å…å†—ä½™
4. å¦‚æœæä¾›äº†å·²æœ‰æ‘˜è¦ï¼Œè¯·åœ¨å…¶åŸºç¡€ä¸Šèåˆæ–°å¯¹è¯å†…å®¹ï¼Œç”Ÿæˆæ›´æ–°ç‰ˆæœ¬çš„æ‘˜è¦
5. æ‘˜è¦åº”å½“ä½¿ç”¨ç¬¬ä¸‰äººç§°`

func (g *LLMSummaryGenerator) buildSummaryPrompt(messages []Message, existingSummary string) string {
	var sb strings.Builder

	if existingSummary != "" {
		sb.WriteString("## å·²æœ‰æ‘˜è¦\n\n")
		sb.WriteString(existingSummary)
		sb.WriteString("\n\n## æ–°å¢å¯¹è¯\n\n")
	} else {
		sb.WriteString("## å¯¹è¯å†…å®¹\n\n")
	}

	for _, msg := range messages {
		switch msg.Role {
		case "user":
			sb.WriteString(fmt.Sprintf("ç”¨æˆ·: %s\n", msg.Content))
		case "assistant":
			sb.WriteString(fmt.Sprintf("åŠ©æ‰‹: %s\n", msg.Content))
		}
	}

	if existingSummary != "" {
		sb.WriteString("\nè¯·åœ¨å·²æœ‰æ‘˜è¦çš„åŸºç¡€ä¸Šï¼Œèåˆæ–°å¢å¯¹è¯å†…å®¹ï¼Œç”Ÿæˆä¸€ä»½æ›´æ–°åçš„å®Œæ•´æ‘˜è¦ã€‚")
	} else {
		sb.WriteString("\nè¯·ä¸ºä»¥ä¸Šå¯¹è¯ç”Ÿæˆä¸€ä»½ç®€æ´çš„æ‘˜è¦ã€‚")
	}

	return sb.String()
}
