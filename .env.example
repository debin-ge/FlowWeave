# ============================================================
# FlowWeave 工作流引擎 — 环境变量配置
# 将此文件复制为 .env 并修改为你的实际值
# ============================================================

# ---------- 全局配置文件（可选） ----------
# 可选：JSON 配置文件路径。加载顺序为：默认值 -> 配置文件 -> 环境变量
# APP_CONFIG_FILE=./config/app.json

# ---------- 服务器 ----------
# HTTP 监听端口
PORT=8080

# ---------- 数据库 ----------
# PostgreSQL 连接字符串（必填）
# 同时用于工作流持久化 和 中期记忆摘要存储
DATABASE_URL=postgres://user:password@localhost:5432/flowweave?sslmode=disable

# ---------- 引擎配置 ----------
# 最大并行工作线程数
ENGINE_MAX_WORKERS=4

# 单节点执行超时（秒）
ENGINE_NODE_TIMEOUT=300

# 工作流最大节点执行步数（防止无限循环）
ENGINE_MAX_NODE_STEPS=100

# ---------- LLM Provider (OpenAI 兼容) ----------
# API Key（必填，用于鉴权）
OPENAI_API_KEY=sk-your-api-key-here

# API 基地址（可接入 OpenAI / Azure / DeepSeek / Ollama 等兼容服务）
OPENAI_BASE_URL=https://api.openai.com/v1

# 默认模型名称
OPENAI_MODEL=gpt-4o-mini

# ---------- 记忆管理 ----------
# Redis 连接字符串（必填，用于短期记忆 STM + 中期记忆缓存 + Gateway 压缩锁）
REDIS_URL=redis://localhost:6379/0

# 中期记忆摘要使用的 LLM Provider（默认 openai）
SUMMARY_LLM_PROVIDER=openai

# 中期记忆摘要使用的模型（默认 gpt-4o-mini，建议用轻量模型节约成本）
SUMMARY_LLM_MODEL=gpt-4o-mini

# ---------- Context-Gateway 压缩 ----------
# 压缩使用的 LLM Provider（默认复用 SUMMARY_LLM_PROVIDER）
GATEWAY_LLM_PROVIDER=openai

# 压缩使用的模型（建议用低成本模型）
GATEWAY_LLM_MODEL=gpt-4o-mini

# 模型上下文窗口大小（Token），用于 Token Budget 计算
# 也可在 DSL 中通过 gateway_compress.context_window_size 覆盖
CONTEXT_WINDOW_SIZE=128000

# 压缩触发 Token 阈值比例（0.70 = 占用上下文窗口 70% 时触发）
# 也可在 DSL 中通过 gateway_compress.token_threshold_ratio 覆盖
COMPRESS_THRESHOLD_RATIO=0.70

# 压缩后最少保留的最近对话轮次
# 也可在 DSL 中通过 gateway_compress.min_recent_turns 覆盖
COMPRESS_MIN_RECENT_TURNS=4

# ---------- 日志 ----------
# 日志级别：debug, info, warn, error
# 设为 debug 可查看记忆模块的详细消息内容预览
LOG_LEVEL=info
# 日志格式：text, json
LOG_FORMAT=text

# ---------- JWT 鉴权（多租户隔离） ----------
# HMAC 签名密钥，设置后启用 JWT 鉴权
# 不设置则跳过鉴权（开发/兼容模式）
JWT_SECRET=test-secret-key-for-dev
# 可选：签发者校验
JWT_ISSUER=

# ---------- RAG 知识检索（可选） ----------
# OpenSearch 连接地址（不设置则 RAG 功能禁用）
OPENSEARCH_URL=https://localhost:9200
OPENSEARCH_USERNAME=admin
OPENSEARCH_PASSWORD=admin
OPENSEARCH_INDEX_PREFIX=rag

# 默认检索模式：bm25 / hybrid / auto
RAG_DEFAULT_MODE=bm25
# 默认返回 Top-K 结果
RAG_DEFAULT_TOP_K=5
# 分块大小（字符数）
RAG_CHUNK_SIZE=512
# 分块重叠（字符数）
RAG_CHUNK_OVERLAP=128

# Embedding（启用 Hybrid 向量检索需要配置）
# 复用 OPENAI_API_KEY / OPENAI_BASE_URL 的网络配置
RAG_EMBEDDING_PROVIDER=openai
RAG_EMBEDDING_MODEL=text-embedding-3-small
RAG_EMBEDDING_DIMS=1536

# Rerank（可选，启用后对 Hybrid 结果做 LLM 精排）
RAG_ENABLE_RERANK=false
RAG_RERANK_PROVIDER=openai
RAG_RERANK_MODEL=gpt-4o-mini

# 检索缓存（Redis，0=禁用）
RAG_CACHE_TTL=300

# 文件上传（最大文件大小，MB）
RAG_MAX_FILE_SIZE=50
